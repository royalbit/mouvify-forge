# ğŸ”¥ Forge - Session Warmup Checklist
# Purpose: Initialize Claude Code sessions with full context and workflow
# Usage: User says "run warmup" or "run warmup.yaml"

session_initialization:
  greeting: "Welcome back! Loading Forge context..."

  step_1_load_context:
    description: "Read these files to understand current state"
    files_to_read:
      - path: "README.md"
        purpose: "Project overview, features, usage examples"

      - path: "roadmap.yaml"
        purpose: "Current version, implementation phases, progress tracking"
        key_sections:
          - "metadata.current_version"
          - "milestones.v1_0_0.implementation_phases"
          - "milestones.v1_0_0.testing_status"

      - path: "DESIGN_V1.md"
        purpose: "v1.0.0 array model specification (800+ lines)"
        key_sections:
          - "Model Structure"
          - "Formula Evaluation"
          - "Type System"
          - "Testing Strategy"

      - path: "KNOWN_BUGS.md"
        purpose: "Documented bugs and workarounds"
        action: "Review before making changes that might affect these areas"

      - path: "SRED_RESEARCH_LOG.md"
        purpose: "ğŸ SR&ED R&D documentation for Canadian tax credits"
        action: "Review existing entries, add new ones for qualifying R&D work"
        importance: "ğŸ’° CRITICAL - this documentation = real money in tax credits"

      - path: "Cargo.toml"
        purpose: "Current version number, dependencies"
        key_fields:
          - "version"
          - "dependencies"

      - path: "schema/forge-v1.0.schema.json"
        purpose: "JSON Schema for v1.0.0 model validation"
        note: "Update when adding new features to v1.0.0 model"

  step_1b_check_current_date:
    description: "CRITICAL: Always check current date for online searches"
    importance: "ğŸš¨ HIGH PRIORITY ğŸš¨"
    rationale: "Claude's training data is several months old (Jan 2025 cutoff)"

    what_to_do:
      - "ALWAYS check <env> tag for Today's date before online searches"
      - "When searching: Add current year/date to query"
      - "Example: 'Rust async 2025' NOT 'Rust async'"
      - "Verify crates.io versions are CURRENT, not from training data"
      - "Check GitHub repos for recent activity before recommending"

    bad_example:
      query: "best rust excel library"
      problem: "Might return 2024 results if Claude assumes old date"

    good_example:
      query: "best rust excel library 2025"
      check_env: "Today's date: 2025-11-23"
      note: "Explicitly include current year in search"

  step_2_git_status:
    description: "Check current branch and uncommitted changes"
    commands:
      - "git status"
      - "git log --oneline -5"
      - "git branch --show-current"
    expected_branch: "feature/v1.0.0-array-model"
    action: "If on different branch, ask user about intent"

  step_2b_validation_baseline:
    description: "Run validation baseline (catch existing issues BEFORE making changes)"
    importance: "ğŸš¨ CRITICAL - Know clean vs dirty state before starting work"
    rationale: |
      Documentation is code. Linting catches consistency issues.
      Must know baseline state to avoid "did I break this or was it already broken?"

    commands:
      markdown_lint:
        command: "make validate-docs"
        tool: "markdownlint-cli2"
        config: ".markdownlint.json"
        install: "npm install -g markdownlint-cli2"
        validates:
          - "README.md"
          - "DESIGN_V1.md"
          - "KNOWN_BUGS.md"
          - "SRED_RESEARCH_LOG.md"
          - "docs/**/*.md"

      yaml_lint:
        command: "make validate-yaml"
        tool: "yamllint"
        config: ".yamllint"
        install: "pip install yamllint"
        validates:
          - "warmup.yaml"
          - "roadmap.yaml"

      full_validation:
        command: "make validate-all"
        runs: "All validators in sequence"
        convenience: "Single command for complete validation"

    if_validation_fails:
      - "Note failures but continue (may be fixing them this session)"
      - "Report baseline status to user"
      - "Track which validators passed/failed"
      - "Include status in greeting"

    reporting:
      template: |
        Validation Baseline:
        - Markdown: [PASS/FAIL - X files]
        - YAML: [PASS/FAIL - X files]

  step_3_run_tests:
    description: "Verify everything works before starting"
    commands:
      - command: "cargo test --lib --release"
        purpose: "Run unit tests"
        expected: "All tests passing"

      - command: "cargo test --release"
        purpose: "Run all tests (unit + integration + e2e)"
        expected: "24-25 e2e tests passing (1 known fuzzy matching issue)"

      - command: "cargo build --release"
        purpose: "Ensure clean build"
        expected: "No warnings or errors"

  step_4_understand_workflow:
    description: "Our development workflow and standards"
    standards:
      testing:
        unit_tests:
          - "100% coverage of new code"
          - "Test happy paths AND edge cases"
          - "Test error conditions"
          - "Use descriptive test names"

        integration_tests:
          - "Test with real v1.0 example files"
          - "Test cross-module interactions"

        e2e_tests:
          - "Test full CLI workflows"
          - "Test with multiple file scenarios"
          - "Test error handling"

        edge_cases:
          - "Empty arrays"
          - "Single-element arrays"
          - "Very large numbers"
          - "Division by zero"
          - "Circular dependencies"
          - "Missing columns"
          - "Type mismatches"
          - "Malformed YAML"

      code_quality:
        - "No warnings in release build (ZERO tolerance)"
        - "Use meaningful variable names"
        - "Add doc comments for public APIs"
        - "Follow existing code style"
        - "Prefer Edit over Write for existing files"

      linting:
        philosophy: "User has OCD for good looking code ğŸ˜Š - use MOST STRICT linting"
        requirements:
          - "Run cargo clippy --all-targets -- -D warnings (treat warnings as errors)"
          - "Use rustfmt with default settings"
          - "No unused imports, variables, or functions"
          - "Prefer explicit over implicit (no _ when you can name it)"
          - "Use clippy pedantic when possible"
        commands:
          - "cargo fmt -- --check (verify formatting)"
          - "cargo clippy --release -- -D warnings (no warnings allowed)"
          - "cargo build --release (must be clean)"

      git_workflow:
        commit_messages:
          format: |
            <Title: imperative mood, 50 chars>

            <Body: what and why, 72 char wrap>

            Key additions:
            - Feature 1
            - Feature 2

            Test coverage: X tests passing

            ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

            Co-Authored-By: Claude <noreply@anthropic.com>

          examples:
            - "Add support for aggregation formulas"
            - "Fix precision issues in array calculator"
            - "Update roadmap with Phase 2 progress"

        commit_strategy:
          - "Commit logical units of work"
          - "Keep commits focused and atomic"
          - "Run tests before committing"
          - "Update roadmap in separate commit"

      sred_documentation:
        description: "ğŸ SR&ED Tax Credits - Document R&D work for Canadian tax credits"
        importance: "ğŸš¨ CRITICAL - Document BEFORE committing"
        file: "SRED_RESEARCH_LOG.md"

        what_is_sred:
          program: "Scientific Research & Experimental Development (Canada)"
          benefit: "Tax credits for R&D work (refundable in some cases)"
          eligibility: "Technical challenges, systematic investigation, technological advancement"

        when_to_document:
          - "ğŸš¨ BEFORE committing new algorithms or data structures"
          - "ğŸš¨ BEFORE committing experimental approaches or optimizations"
          - "ğŸš¨ BEFORE committing solutions to technical uncertainties"
          - "After resolving performance issues"
          - "After experimenting with alternative approaches"
          - "When creating novel abstractions or patterns"

        what_to_document:
          technical_challenge:
            - "What problem are we solving?"
            - "Why is it technically uncertain?"
            - "What makes it non-trivial/non-obvious?"
          hypothesis:
            - "What approach did we try?"
            - "What alternatives did we consider?"
            - "Why did we choose this approach?"
          experiment:
            - "What did we implement?"
            - "What tests did we run?"
            - "What measurements did we take?"
          results:
            - "Did it work? Why or why not?"
            - "What did we learn?"
            - "Were there unexpected findings?"
          advancement:
            - "What new capability did we create?"
            - "How does it advance the state of the art?"
            - "What can users now do that they couldn't before?"

        qualifying_activities:
          yes:
            - "âœ… Algorithm design and optimization"
            - "âœ… Performance analysis and improvements"
            - "âœ… Experimental testing approaches (property-based, mutation, fuzzing)"
            - "âœ… Resolving technical uncertainties"
            - "âœ… Creating novel data structures and abstractions"
            - "âœ… Dependency resolution algorithms"
            - "âœ… Type system design"
          no:
            - "âŒ Routine coding (following established patterns)"
            - "âŒ UI design and styling"
            - "âŒ Documentation writing (unless documenting research)"
            - "âŒ Bug fixes for simple typos"
            - "âŒ Standard library integration"

        workflow:
          - "1ï¸âƒ£ Identify if work qualifies for SR&ED (see qualifying_activities)"
          - "2ï¸âƒ£ If YES: Document in SRED_RESEARCH_LOG.md DURING development"
          - "3ï¸âƒ£ Include: Challenge, Hypothesis, Experiment, Results, Advancement"
          - "4ï¸âƒ£ Be specific about technical challenges and alternatives considered"
          - "5ï¸âƒ£ Link to commits, test results, benchmarks"
          - "6ï¸âƒ£ THEN commit code"

        example_entry_title:
          - "Entry X: Aggregation Formula Evaluation (Phase 2 Part 2)"
          - "Entry X: Zero-Copy String Optimization"
          - "Entry X: Property-Based Testing for Formula Invariants"

        reminder: "ğŸ’° This documentation = real money in tax credits. Don't skip it!"

      diagrams:
        description: "ğŸ“Š Mermaid architecture and design diagrams"
        importance: "Visual documentation for complex systems"
        format: "Embedded Mermaid in markdown files"
        rendering: "GitHub renders Mermaid natively"

        when_to_create:
          major_versions:
            - "New major release (v1.0, v2.0) - architecture overview"
            - "Significant architectural changes - component diagrams"
            - "New subsystems - integration diagrams"
          complex_features:
            - "Multi-step workflows - sequence diagrams"
            - "Decision logic - flowcharts"
            - "Data model changes - class diagrams"
          documentation:
            - "README needs visual aid - architecture diagram"
            - "DESIGN_V1 explaining algorithms - flow diagram"
            - "SRED explaining novel approach - sequence/component diagram"

        diagram_types:
          flowchart:
            when: "System architecture, data flow, decision logic"
            example: "graph TB for top-bottom, graph LR for left-right"
          sequence:
            when: "User workflows, cross-component interactions"
            example: "sequenceDiagram for time-based flows"
          class:
            when: "Data models, type systems"
            example: "classDiagram for type hierarchies"
          er:
            when: "Data relationships"
            example: "erDiagram for database schemas"

        workflow:
          - "1ï¸âƒ£ Embed Mermaid directly in markdown file"
          - "2ï¸âƒ£ Use ```mermaid code fence"
          - "3ï¸âƒ£ Preview on GitHub (renders automatically)"
          - "4ï¸âƒ£ No separate validation needed (GitHub validates on render)"
          - "5ï¸âƒ£ Commit markdown file with embedded diagram"

        best_practices:
          - "Use clear, descriptive node labels"
          - "Add comments with %% in Mermaid code"
          - "Check GLOSSARY.md for canonical term names"
          - "Keep focused: max 15-20 elements per diagram"
          - "Use subgraphs for logical grouping"
          - "ğŸš¨ CRITICAL: Use VANILLA Mermaid (no theme/color customization)"

        github_theming_rules:
          critical_rule: "DO NOT customize themes or colors - breaks GitHub auto-detection"
          what_breaks_auto_theming:
            - "âŒ %%{init: {'theme': 'dark'}}%% - theme directives"
            - "âŒ classDef myStyle fill:#90EE90 - custom colors"
            - "âŒ class nodeX myStyle - applying custom styles"
          what_is_safe:
            - "âœ… Standard shapes: [], [()], [()] - Mermaid syntax"
            - "âœ… Arrow labels: -->|text| - standard syntax"
            - "âœ… Subgraphs: subgraph name - standard syntax"
            - "âœ… Emojis in labels: ['ğŸ”¥ Text'] - just Unicode text"
            - "âœ… Line breaks: <br/> - standard HTML"
          why_vanilla_works:
            - "GitHub auto-detects user's light/dark theme preference"
            - "GitHub applies appropriate colors automatically"
            - "ANY customization overrides this and breaks on one theme"
            - "Vanilla Mermaid = works perfectly on BOTH light and dark"
          tested_and_verified: "2025-11-24 - tested on GitHub with dark theme user"

        resources:
          docs: "https://mermaid.js.org/"
          live_editor: "https://mermaid.live/"
          github_docs: "https://github.blog/2022-02-14-include-diagrams-markdown-files-mermaid/"
          stackoverflow: "https://stackoverflow.com/questions/75827387"
          github_community: "https://github.com/orgs/community/discussions/35733"

        reminder: "ğŸ“Š Use VANILLA Mermaid on GitHub - let GitHub handle themes automatically!"

      documentation:
        update_when:
          - "Adding new features â†’ Update README.md"
          - "Changing model structure â†’ Update DESIGN_V1.md and schema"
          - "Completing phases â†’ Update roadmap.yaml"
          - "Discovering bugs â†’ Update KNOWN_BUGS.md"
          - "Adding CLI flags â†’ Update --help text"
          - "Changing API â†’ Add doc comments"

library_and_dependency_management:
  philosophy: "Don't reinvent the wheel - leverage FOSS ecosystem"

  before_implementing_complex_code:
    description: "Check for existing FOSS libraries BEFORE writing complex code"
    steps:
      - "Search crates.io for relevant functionality"
      - "Check license compatibility (we use MIT)"
      - "Verify library is maintained (recent commits, active issues)"
      - "Check download counts and GitHub stars"
      - "Review documentation quality"
      - "Test with small example before integrating"

    compatible_licenses:
      perfect:
        - "MIT"
        - "Apache-2.0"
        - "BSD-2-Clause"
        - "BSD-3-Clause"
      acceptable:
        - "ISC"
        - "Unlicense"
        - "CC0-1.0"
      incompatible:
        - "GPL (any version) - copyleft, conflicts with MIT"
        - "AGPL - copyleft"
        - "LGPL - complicated compatibility"

    evaluation_checklist:
      - "â˜ License is MIT-compatible"
      - "â˜ Last commit within 6 months"
      - "â˜ Has documentation"
      - "â˜ No critical security issues"
      - "â˜ Reasonable download count (or new but promising)"
      - "â˜ Solves our problem completely (or mostly)"

    example_workflow:
      scenario: "Need to export to Excel"
      step_1: "Search: 'rust excel xlsx 2025' (include current year!)"
      step_2: "Check top results: rust_xlsxwriter, calamine, umya-spreadsheet"
      step_3: "Review licenses: rust_xlsxwriter (MIT âœ…), calamine (MIT âœ…)"
      step_4: "Check maintenance: rust_xlsxwriter (active âœ…)"
      step_5: "Read docs: rust_xlsxwriter has good examples âœ…"
      step_6: "Decision: Use rust_xlsxwriter"
      dont_do: "Write Excel export from scratch (thousands of lines!)"

  keeping_dependencies_updated:
    description: "Regularly update dependencies to latest versions"
    importance: "Security, bug fixes, performance, new features"

    when_to_update:
      - "Start of new implementation phase"
      - "Before release"
      - "When security advisory published"
      - "When new feature needed from dependency"

    how_to_update:
      check_outdated:
        command: "cargo outdated"
        install: "cargo install cargo-outdated"
        purpose: "Shows which dependencies have updates"

      update_minor:
        command: "cargo update"
        purpose: "Update to latest compatible versions (respects Cargo.toml semver)"
        safe: "Yes - follows semver"

      update_major:
        steps:
          - "Review CHANGELOG for breaking changes"
          - "Update Cargo.toml version requirement"
          - "Run cargo update"
          - "Fix any breaking changes"
          - "Run full test suite"
        caution: "May require code changes"

      update_all:
        command: "cargo upgrade"
        install: "cargo install cargo-edit"
        purpose: "Upgrade all deps to latest (including major versions)"
        caution: "Test thoroughly after this!"

    testing_after_update:
      - "cargo test --release (all tests must pass)"
      - "cargo clippy --release (no new warnings)"
      - "cargo build --release (verify compilation)"
      - "Run key e2e tests manually"

    current_dependencies:
      note: "Check Cargo.toml for current versions"
      critical_deps:
        - "xlformula_engine - Excel formula engine"
        - "serde/serde_yaml - YAML parsing"
        - "clap - CLI parsing"
        - "petgraph - Dependency graph"
        - "jsonschema - JSON Schema validation"

work_session_checklist:
  before_coding:
    - "â˜ Read warmup.yaml (this file)"
    - "â˜ CHECK CURRENT DATE in <env> (for online searches!)"
    - "â˜ Run validation baseline (make validate-all)"
    - "â˜ Load context files (README, roadmap, DESIGN_V1, KNOWN_BUGS, GLOSSARY)"
    - "â˜ Check git status and current branch"
    - "â˜ Run tests to verify baseline (cargo test --release)"
    - "â˜ Review current phase in roadmap"
    - "â˜ Check if dependencies need updating (cargo outdated)"
    - "â˜ Create TodoWrite list for session goals"

  during_coding:
    - "â˜ BEFORE complex code: Check for FOSS libraries (crates.io search)"
    - "â˜ Write tests FIRST (TDD when possible)"
    - "â˜ Test edge cases thoroughly"
    - "â˜ Check GLOSSARY.md for terminology consistency"
    - "â˜ ğŸ Document R&D work in SRED_RESEARCH_LOG.md DURING development"
    - "â˜ Update JSON Schema if model changes"
    - "â˜ Document bugs in KNOWN_BUGS.md if found"
    - "â˜ Update TodoWrite list as you progress"
    - "â˜ Run tests frequently (cargo test --lib)"
    - "â˜ Run clippy frequently (cargo clippy --release)"
    - "â˜ Format code frequently (cargo fmt)"

  after_coding:
    - "â˜ Run cargo fmt (format code)"
    - "â˜ Run cargo clippy --release -- -D warnings (ZERO warnings!)"
    - "â˜ Run full test suite (cargo test --release)"
    - "â˜ Ensure clean build (cargo build --release)"
    - "â˜ Run validation (make validate-all - markdown + YAML)"
    - "â˜ Update documentation (README, DESIGN_V1, roadmap)"
    - "â˜ Update --help if CLI changed"
    - "â˜ Check terminology consistency (GLOSSARY.md)"
    - "â˜ ğŸ VERIFY SR&ED documentation complete BEFORE committing (ğŸ’° tax credits!)"
    - "â˜ Git add and commit with good message"
    - "â˜ Update roadmap in separate commit"
    - "â˜ Push to remote (git push)"

  completing_phase:
    - "â˜ All phase features implemented"
    - "â˜ 100% test coverage with edge cases"
    - "â˜ Documentation complete"
    - "â˜ Roadmap updated (phase status: completed)"
    - "â˜ Git push"
    - "â˜ Discuss release strategy with user"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤– AUTONOMOUS WORK REQUIREMENTS - IRONCLAD RULES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# These are NON-NEGOTIABLE requirements when working autonomously.
# Violation of ANY of these means the work is NOT production-ready.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

autonomous_work_requirements:
  philosophy: |
    When user says "work independently" or gives autonomous instructions,
    these requirements are MANDATORY. No shortcuts. No "almost done".
    Production-ready means ALL requirements met.

  testing_requirements:
    description: "100% test coverage is NON-NEGOTIABLE"

    unit_tests_required:
      - rule: "EVERY public function MUST have unit tests"
      - rule: "EVERY error path MUST be tested"
      - rule: "EVERY edge case MUST be covered"
      - examples:
          - "Empty inputs (empty strings, empty arrays, nulls)"
          - "Boundary values (0, negative, MAX_INT)"
          - "Invalid inputs (malformed data, wrong types)"
          - "Large inputs (1000+ rows, deeply nested structures)"

    e2e_tests_required:
      - rule: "EVERY user-facing command MUST have e2e tests"
      - rule: "E2E tests MUST use REAL test files (not mocks)"
      - rule: "E2E tests MUST cover happy path + failure modes"
      - examples:
          - "forge calculate: success case + stale values + errors"
          - "forge validate: passing + failing validation"
          - "forge export: YAML â†’ Excel with formulas"
          - "forge import: Excel â†’ YAML with formula translation"
          - "Round-trip: YAML â†’ Excel â†’ YAML (must be identical!)"

    test_data_required:
      - rule: "Create REAL test files in test-data/ directory"
      - rule: "Include edge case test files (empty, large, malformed)"
      - examples:
          - "test-data/export_basic.yaml (simple export test)"
          - "test-data/export_with_formulas.yaml (formula translation)"
          - "test-data/import_basic.xlsx (Excel import test)"
          - "test-data/import_with_formulas.xlsx (reverse translation)"
          - "test-data/roundtrip.yaml (start here, export, import, compare)"
          - "test-data/edge_cases/ (empty sheets, 1000+ rows, malformed)"

    coverage_verification:
      - command: "cargo test --release"
      - requirement: "ALL tests MUST pass (not 99%, ALL)"
      - command: "cargo test --release -- --nocapture"
      - requirement: "Run e2e tests and VERIFY actual files created/read"
      - verification: "Manually check test-data/ files exist and are correct"

  code_quality_requirements:
    description: "ZERO tolerance for warnings or errors"

    compilation:
      - command: "cargo build --release"
      - requirement: "MUST succeed with ZERO errors"
      - note: "If it doesn't compile, it's not done"

    linting:
      - command: "cargo clippy --release -- -D warnings"
      - requirement: "MUST pass with ZERO warnings"
      - note: "User has OCD for good looking code - use MOST STRICT linting"
      - action: "Fix ALL warnings before considering work complete"

    formatting:
      - command: "cargo fmt"
      - requirement: "MUST be run before every commit"
      - note: "Consistent formatting = professional code"

  documentation_requirements:
    description: "Documentation MUST be complete and accurate"

    inline_documentation:
      - rule: "EVERY public function MUST have doc comments"
      - rule: "Doc comments MUST include examples for non-trivial functions"
      - rule: "Error conditions MUST be documented"

    readme_updates:
      - rule: "README.md MUST reflect ALL new features"
      - rule: "CLI --help (src/main.rs) MUST match README messaging"
      - rule: "Usage examples MUST be tested and working"
      - rule: "Installation instructions MUST be current"
      - note: "Users see --help before README - keep them in sync!"

    roadmap_updates:
      - rule: "roadmap.yaml MUST be updated with phase completion"
      - rule: "current_version MUST match Cargo.toml"
      - rule: "Completed phases MUST be marked with timestamps"

    sred_documentation:
      - rule: "ğŸ SRED_RESEARCH_LOG.md MUST be updated for R&D work"
      - importance: "ğŸ’° CRITICAL - this = real money in tax credits"
      - requirement: "Document uncertainties, hypotheses, experiments, results"
      - frequency: "DURING development, not after"

  feature_completeness:
    description: "Features MUST be fully implemented, not partially"

    definition_of_done:
      - "âœ… Implementation complete (not 'mostly done')"
      - "âœ… Unit tests written and passing"
      - "âœ… E2E tests written and passing"
      - "âœ… Edge cases tested"
      - "âœ… Error handling tested"
      - "âœ… Documentation updated (inline, README, roadmap)"
      - "âœ… SR&ED documentation updated"
      - "âœ… ZERO warnings from clippy"
      - "âœ… Code formatted with cargo fmt"
      - "âœ… Git committed with descriptive message"

    not_done_if:
      - "âŒ Tests are commented out or skipped"
      - "âŒ TODO comments remain for core functionality"
      - "âŒ Error handling is missing or uses unwrap()"
      - "âŒ Documentation is placeholder or outdated"
      - "âŒ Clippy warnings exist ('I'll fix them later')"
      - "âŒ E2E tests don't exist for user-facing commands"
      - "âŒ Test data files don't exist"

  autonomous_work_checklist:
    description: "Use this checklist when working autonomously"

    before_starting:
      - "â˜ Read and understand user's autonomous instruction"
      - "â˜ Create TodoWrite list with ALL tasks (implementation + tests + docs)"
      - "â˜ Identify what tests need to be created (unit + e2e + test data)"
      - "â˜ Verify baseline: all existing tests passing"

    during_implementation:
      - "â˜ Write unit tests FIRST or alongside implementation"
      - "â˜ Create test data files as you go"
      - "â˜ Test edge cases (empty, null, invalid, large)"
      - "â˜ Document uncertainties in SR&ED log"
      - "â˜ Run tests frequently (cargo test)"
      - "â˜ Fix warnings immediately (don't accumulate)"

    after_implementation:
      - "â˜ Write e2e tests for ALL user-facing commands"
      - "â˜ Verify e2e tests with REAL files (not mocks)"
      - "â˜ Test round-trip scenarios (if applicable)"
      - "â˜ Run cargo clippy --release -- -D warnings â†’ ZERO warnings"
      - "â˜ Run cargo test --release â†’ ALL passing"
      - "â˜ Update inline documentation"
      - "â˜ Update README.md with new features"
      - "â˜ Update roadmap.yaml with completion status"
      - "â˜ Update SR&ED log with final results"
      - "â˜ Run cargo fmt"
      - "â˜ Git commit with descriptive message"

    before_reporting_complete:
      - "â˜ Double-check: ALL tests passing?"
      - "â˜ Double-check: ZERO clippy warnings?"
      - "â˜ Double-check: E2E tests exist and pass?"
      - "â˜ Double-check: Test data files exist?"
      - "â˜ Double-check: Documentation updated?"
      - "â˜ Double-check: SR&ED log updated?"
      - "â˜ If ANY checkbox unchecked â†’ NOT DONE, keep working"

  success_criteria:
    description: "How to know autonomous work is truly complete"

    technical_criteria:
      - "âœ… cargo build --release â†’ success"
      - "âœ… cargo test --release â†’ all tests pass"
      - "âœ… cargo clippy --release -- -D warnings â†’ zero warnings"
      - "âœ… cargo fmt â†’ already formatted"
      - "âœ… E2E tests exist for every user command"
      - "âœ… Test data files exist in test-data/"
      - "âœ… Round-trip tests pass (if applicable)"

    documentation_criteria:
      - "âœ… README.md reflects new features"
      - "âœ… roadmap.yaml shows completion"
      - "âœ… SRED_RESEARCH_LOG.md updated"
      - "âœ… Inline docs complete"

    quality_criteria:
      - "âœ… No unwrap() in library code"
      - "âœ… No TODOs for core functionality"
      - "âœ… Error messages are helpful"
      - "âœ… Edge cases handled gracefully"

    user_experience_criteria:
      - "âœ… Commands work as user expects"
      - "âœ… Error messages guide user to solution"
      - "âœ… Examples in README work when copy-pasted"
      - "âœ… Installation instructions are current"

  lessons_learned:
    v1_0_0_gap: |
      v1.0.0 was released with excellent unit tests for FormulaTranslator and
      ReverseFormulaTranslator, BUT missing e2e tests for `forge export` and
      `forge import` commands. This gap meant the core USER-FACING features
      were not tested end-to-end with real .xlsx files.

      LESSON: Unit tests alone are NOT enough. E2E tests for every user command
      are MANDATORY. Create test-data/*.xlsx files and verify round-trips.

      This is why these autonomous work requirements now exist.

release_workflow:
  overview:
    description: "Complete release protocol - comprehensive, production-ready"
    when_to_use: "When releasing a new version to crates.io and GitHub"
    estimated_time: "30-45 minutes for full process"

  step_1_documentation_audit:
    description: "Verify ALL documentation is updated and consistent"
    critical: "ğŸš¨ MANDATORY - catches documentation drift"

    locations_to_check:
      cli_help:
        file: "src/main.rs"
        what: "CLI --help text (long_about)"
        verify:
          - "Function count matches reality (e.g., 50+ functions)"
          - "New features listed with examples"
          - "Version-specific notes (v1.1.0, v1.2.0, etc.)"

      architecture_docs:
        files:
          - "docs/architecture/00-OVERVIEW.md"
          - "docs/architecture/03-FORMULA-EVALUATION.md"
          - "docs/architecture/06-CLI-ARCHITECTURE.md"
        verify:
          - "Supported Functions list includes ALL functions"
          - "Function count consistent (50+ everywhere)"
          - "New features documented with signatures"
          - "CLI help example matches src/main.rs"

      changelog:
        file: "CHANGELOG.md"
        verify:
          - "[Unreleased] section exists for current version"
          - "All new features documented with signatures"
          - "Breaking changes clearly marked"
          - "Testing stats updated (e.g., 141 tests passing)"
          - "Development time documented"

      readme:
        file: "README.md"
        verify:
          - "What's New section matches CHANGELOG"
          - "Feature list complete"
          - "Function count matches (50+)"
          - "Examples work with current version"

      roadmap:
        file: "roadmap.yaml"
        verify:
          - "Current version status: in_progress or completed"
          - "Progress section updated with completion dates"
          - "Next version planned"

    command: "Run documentation audit checklist above manually"

  step_2_comprehensive_testing:
    description: "Test EVERYTHING - unit, integration, E2E, edge cases"
    critical: "ğŸš¨ MANDATORY - zero bugs shipped"

    unit_tests:
      command: "cargo test --lib --release"
      expected: "All tests pass, zero warnings"
      what_it_tests:
        - "All Excel functions (50+ functions)"
        - "Edge cases: empty arrays, type mismatches, boundaries"
        - "Lookup functions: MATCH, INDEX, XLOOKUP, VLOOKUP"
        - "Formula parsing and evaluation"
        - "Type conversions and validations"

    integration_tests:
      command: "cargo test --test integration_tests --release"
      expected: "All integration tests pass"
      what_it_tests:
        - "Cross-file references"
        - "Multi-table calculations"
        - "Complex formula chains"

    e2e_tests:
      command: "cargo test --test e2e_tests --release"
      expected: "All E2E tests pass (typically 33+ tests)"
      what_it_tests:
        - "CLI commands: calculate, validate, export, import, audit"
        - "Excel import/export with formula translation"
        - "Roundtrip: YAML â†’ Excel â†’ YAML preservation"
        - "Error handling: malformed files, circular dependencies"
        - "Cross-file includes and dependencies"
        - "Stale value detection"

    all_tests:
      command: "cargo test --release"
      expected: "140+ tests passing, ZERO failures"
      note: "This runs all test suites above"

    edge_case_coverage_checklist:
      lookup_functions:
        - "â˜ MATCH: exact, ascending approximate, descending approximate"
        - "â˜ MATCH: not found scenarios"
        - "â˜ INDEX: valid position, out of bounds"
        - "â˜ XLOOKUP: exact match, if_not_found"
        - "â˜ VLOOKUP: basic (note: limited implementation)"
        - "â˜ Cross-table lookups: INDEX(MATCH(...)) pattern"
      excel_functions:
        - "â˜ All 27 v1.1.0 functions tested"
        - "â˜ Empty arrays, null values"
        - "â˜ Type mismatches (text in numeric function)"
        - "â˜ Boundary conditions (division by zero, negative dates)"
      excel_integration:
        - "â˜ Import: numbers, text, dates, booleans, formulas"
        - "â˜ Export: formula translation (60+ Excel functions)"
        - "â˜ Roundtrip: data and formula preservation"
        - "â˜ Multiple tables, cross-sheet references"
        - "â˜ Edge cases: empty cells, malformed data"

  step_3_lint_all:
    description: "Lint code and documentation"
    critical: "Required for production quality"

    rust_lint:
      command: "cargo clippy --all-targets -- -D warnings"
      expected: "ZERO warnings (strict mode)"
      note: "If warnings exist, fix them before release"

    rust_format:
      command: "cargo fmt -- --check"
      expected: "No formatting changes needed"
      fix_command: "cargo fmt"

    markdown_lint:
      command: "make validate-docs"
      expected: "<50 errors (edge cases only acceptable)"
      note: "Fix critical errors, edge cases can wait"

    yaml_lint:
      command: "make validate-yaml"
      expected: "ZERO errors"
      critical: "YAML errors = data corruption risk"

    plantuml_diagrams:
      command: "make validate-diagrams"
      expected: "All diagrams valid"
      note: "Only if diagrams exist"

  step_4_version_bump:
    description: "Update version across all files"

    version_strategy:
      major: "Breaking changes (1.0.0 â†’ 2.0.0)"
      minor: "New features, backwards compatible (1.1.0 â†’ 1.2.0)"
      patch: "Bug fixes (1.1.0 â†’ 1.1.1)"

    files_to_update:
      cargo_toml:
        file: "Cargo.toml"
        field: "version = \"X.Y.Z\""
        example: "version = \"1.2.0\""

      roadmap:
        file: "roadmap.yaml"
        field: "metadata.current_version"
        example: "current_version: \"1.2.0\""

      changelog:
        file: "CHANGELOG.md"
        action: "Change [Unreleased] to [X.Y.Z] - YYYY-MM-DD"
        example: "## [1.2.0] - 2025-11-24"

      readme:
        file: "README.md"
        action: "Update 'What's New' section title"
        example: "## ğŸ† What's New in v1.2.0"

    command_sequence:
      - "Update Cargo.toml version"
      - "Update roadmap.yaml current_version"
      - "Update CHANGELOG.md [Unreleased] â†’ [X.Y.Z] - DATE"
      - "Update README.md 'What's New' â†’ 'What Was New'"
      - "git add Cargo.toml roadmap.yaml CHANGELOG.md README.md"
      - "git commit -m 'chore: Bump version to vX.Y.Z'"

  step_5_commit_and_push:
    description: "Commit release and push to main"

    commands:
      - command: "git add -A"
        note: "Stage all changes"

      - command: "git status"
        note: "Review what's being committed"

      - command: "git commit -m 'release: vX.Y.Z - <title>'"
        example: "git commit -m 'release: v1.2.0 - Lookup Functions (MATCH, INDEX, XLOOKUP, VLOOKUP)'"
        note: "Use conventional commit format"

      - command: "git push origin main"
        note: "Push to GitHub main branch"

  step_6_build_release_binary:
    description: "Build optimized production binary"

    build_command:
      command: "cargo build --release"
      expected: "Successful build in target/release/forge"
      time: "~2-3 minutes"

    strip_binary:
      command: "strip target/release/forge"
      purpose: "Remove debug symbols, reduce size"
      note: "Optional but recommended"

    compress_binary:
      command: "tar -czf forge-vX.Y.Z-linux-x86_64.tar.gz -C target/release forge"
      example: "tar -czf forge-v1.2.0-linux-x86_64.tar.gz -C target/release forge"
      output: "forge-vX.Y.Z-linux-x86_64.tar.gz (~2-3 MB compressed)"

    verify_binary:
      command: "./target/release/forge --version"
      expected: "forge X.Y.Z"

  step_7_install_locally:
    description: "Test local installation"

    using_makefile:
      command: "make install"
      installs_to: "/usr/local/bin/forge"
      requires: "sudo access"

    using_cargo:
      command: "cargo install --path . --force"
      installs_to: "~/.cargo/bin/forge"
      note: "Rebuilds and installs from source"

    verify_installation:
      command: "forge --version"
      expected: "forge X.Y.Z"
      command2: "which forge"
      expected2: "/usr/local/bin/forge or ~/.cargo/bin/forge"

  step_8_publish_to_crates_io:
    description: "Publish to crates.io registry"
    critical: "ğŸš¨ IRREVERSIBLE - cannot unpublish versions"

    prerequisites:
      - "â˜‘ All tests passing (step 2)"
      - "â˜‘ All lints clean (step 3)"
      - "â˜‘ Version bumped (step 4)"
      - "â˜‘ Changes committed and pushed (step 5)"
      - "â˜‘ Binary built and tested (step 6-7)"

    get_api_key:
      command: "pass crates.io"
      note: "Retrieves API token from password manager"
      alternative: "Get from https://crates.io/settings/tokens"

    login:
      command: "cargo login <API_KEY>"
      note: "Only needed once per machine"
      stored_in: "~/.cargo/credentials.toml"

    dry_run:
      command: "cargo publish --dry-run"
      purpose: "Verify package before publishing"
      checks:
        - "All files included"
        - "No large files (>10 MB warning)"
        - "Dependencies resolvable"
        - "Manifest valid"

    publish:
      command: "cargo publish"
      expected: "Uploading royalbit-forge vX.Y.Z"
      time: "~30-60 seconds"
      output: "Published successfully"

    verify_publication:
      wait: "2-3 minutes for crates.io to index"
      command: "Open https://crates.io/crates/royalbit-forge"
      check:
        - "New version visible"
        - "Documentation link works"
        - "Download count incrementing"

    test_installation:
      command: "cargo install royalbit-forge --version X.Y.Z"
      note: "Test in separate directory/machine"
      verify: "forge --version shows X.Y.Z"

  step_9_create_github_release:
    description: "Create GitHub release with binary and notes"

    create_git_tag:
      command: "git tag -a vX.Y.Z -m 'vX.Y.Z: <Short description>'"
      example: "git tag -a v1.2.0 -m 'v1.2.0: Lookup Functions (MATCH, INDEX, XLOOKUP, VLOOKUP)'"
      note: "Annotated tags include metadata"

    push_tag:
      command: "git push origin vX.Y.Z"
      example: "git push origin v1.2.0"

    create_release:
      command: |
        gh release create vX.Y.Z \
          --title "vX.Y.Z: <Title> ğŸ”¥" \
          --notes-file RELEASE_NOTES.md \
          forge-vX.Y.Z-linux-x86_64.tar.gz
      example: |
        gh release create v1.2.0 \
          --title "v1.2.0: Lookup Functions ğŸ”¥" \
          --notes "$(cat <<'EOF'
        ## ğŸ‰ Lookup Functions Release

        **4 powerful lookup functions for cross-table data relationships:**

        - **MATCH** - Find position in array (exact/approximate)
        - **INDEX** - Return value at position (1-based)
        - **XLOOKUP** - Modern Excel lookup with if_not_found
        - **VLOOKUP** - Classic lookup (limited, use INDEX/MATCH)

        **Combined:** Use INDEX(MATCH(...)) for flexible lookups!

        ### Quality
        - âœ… 141 tests passing (+5 new)
        - âœ… Zero clippy warnings
        - âœ… 690 lines production code
        - âœ… <3 hours autonomous development

        ### Installation
        \`\`\`bash
        cargo install royalbit-forge
        \`\`\`

        Or download binary: forge-v1.2.0-linux-x86_64.tar.gz

        **Full changelog:** [CHANGELOG.md](CHANGELOG.md)
        EOF
        )" \
          forge-v1.2.0-linux-x86_64.tar.gz

    verify_release:
      command: "Open https://github.com/royalbit/forge/releases"
      check:
        - "New release visible"
        - "Binary attached and downloadable"
        - "Release notes formatted correctly"
        - "Tag linked properly"

  step_10_update_crate_page:
    description: "Update crates.io metadata (if needed)"
    note: "Usually automatic from Cargo.toml, but verify"

    what_syncs_automatically:
      - "Description (from Cargo.toml description)"
      - "Documentation link (from Cargo.toml documentation)"
      - "Repository link (from Cargo.toml repository)"
      - "License (from Cargo.toml license)"
      - "README (from README.md)"
      - "Categories and keywords (from Cargo.toml)"

    manual_updates:
      url: "https://crates.io/crates/royalbit-forge/settings"
      can_update:
        - "Crate owners"
        - "README content (if not auto-syncing)"
        - "Yanking versions (if critical bug found)"

    verify_metadata:
      check:
        - "â˜ Description clear and accurate"
        - "â˜ Documentation link works"
        - "â˜ Repository link works"
        - "â˜ README renders correctly"
        - "â˜ Keywords help discoverability"

  step_11_post_release_verification:
    description: "Final verification and cleanup"

    verification_checklist:
      - "â˜ crates.io shows new version: https://crates.io/crates/royalbit-forge"
      - "â˜ GitHub release exists: https://github.com/royalbit/forge/releases"
      - "â˜ Binary downloadable and works"
      - "â˜ cargo install royalbit-forge installs new version"
      - "â˜ Documentation builds: https://docs.rs/royalbit-forge"
      - "â˜ forge --version shows correct version"
      - "â˜ All tests still passing: cargo test"

    update_roadmap:
      file: "roadmap.yaml"
      action: "Mark milestone as completed"
      example: |
        v1_2_0:
          status: completed  # was: in_progress
          released_date: "2025-11-24"

    create_next_milestone:
      action: "Start planning next version"
      tasks:
        - "Create roadmap entry for vX.Y+1.0"
        - "Identify next features from backlog"
        - "Update CHANGELOG.md with [Unreleased] section"

    social_media:
      optional: "Share release on social media"
      platforms:
        - "Twitter/X: New version of Forge released!"
        - "LinkedIn: Professional announcement"
        - "Reddit: r/rust announcement (follow subreddit rules)"
        - "Hacker News: Show HN (if major release)"

  troubleshooting:
    crates_io_publish_fails:
      error: "crate version already exists"
      solution: "Bump version in Cargo.toml, can't overwrite published versions"

    crates_io_publish_fails_token:
      error: "authentication token invalid"
      solution: "cargo login <API_KEY> with fresh token from crates.io/settings/tokens"

    github_release_fails:
      error: "tag already exists"
      solution: "Delete tag: git tag -d vX.Y.Z && git push origin :refs/tags/vX.Y.Z"

    binary_not_found:
      error: "forge-vX.Y.Z-linux-x86_64.tar.gz not found"
      solution: "Run step 6 (build release binary) first"

    tests_failing:
      error: "Some tests fail"
      solution: "DO NOT RELEASE. Fix tests first. ZERO failures required."

  release_example_session:
    description: "Complete example of v1.2.0 release"
    commands: |
      # Step 1: Documentation audit (manual checklist)
      # Step 2: Test everything
      cargo test --release
      # â†’ 141 tests passing âœ…

      # Step 3: Lint all
      cargo clippy --all-targets -- -D warnings
      make validate-docs
      make validate-yaml
      # â†’ All clean âœ…

      # Step 4: Version bump
      # Edit Cargo.toml: version = "1.2.0"
      # Edit roadmap.yaml: current_version: "1.2.0"
      # Edit CHANGELOG.md: ## [1.2.0] - 2025-11-24
      git add -A
      git commit -m "chore: Bump version to v1.2.0"

      # Step 5: Push
      git push origin main

      # Step 6: Build binary
      cargo build --release
      strip target/release/forge
      tar -czf forge-v1.2.0-linux-x86_64.tar.gz -C target/release forge

      # Step 7: Install locally
      make install
      forge --version  # â†’ forge 1.2.0 âœ…

      # Step 8: Publish to crates.io
      pass crates.io  # â†’ get API key
      cargo login <API_KEY>
      cargo publish --dry-run  # â†’ verify
      cargo publish  # â†’ publish âœ…

      # Wait 2-3 minutes for indexing

      # Step 9: GitHub release
      git tag -a v1.2.0 -m "v1.2.0: Lookup Functions"
      git push origin v1.2.0
      gh release create v1.2.0 \
        --title "v1.2.0: Lookup Functions ğŸ”¥" \
        --notes "<release notes>" \
        forge-v1.2.0-linux-x86_64.tar.gz

      # Step 10: Verify crates.io page (automatic)

      # Step 11: Post-release verification
      cargo install royalbit-forge --version 1.2.0
      # Update roadmap.yaml status: completed

      # ğŸ‰ Release complete!

known_issues:
  fuzzy_matching_bug:
    file: "KNOWN_BUGS.md"
    status: "Documented, not blocking v1.0.0"
    description: "Fuzzy variable matching too permissive (@invalid_alias matches @pricing)"
    workaround: "Use exact names or fix in post-1.0.0"

current_implementation_focus:
  phase: "Phase 2: Array-aware Calculator"
  status: "In progress (50%)"
  next_steps:
    - "Implement aggregation formulas (SUM, AVERAGE)"
    - "Add table.column reference parsing"
    - "Implement cross-table references"
    - "Add array indexing (revenue[0])"
    - "Test with v1.0 example files"

key_files_map:
  source:
    - "src/types.rs - Type definitions (ForgeVersion, ColumnValue, Table, ParsedModel)"
    - "src/parser/mod.rs - Parsing logic (parse_model for unified parsing)"
    - "src/core/calculator.rs - v0.2.0 scalar calculator"
    - "src/core/array_calculator.rs - v1.0.0 array calculator"
    - "src/cli/commands.rs - CLI command implementations"

  tests:
    - "tests/parser_v1_tests.rs - v1.0 parser integration tests"
    - "tests/array_calculator_tests.rs - Array calculator tests"
    - "tests/e2e_tests.rs - End-to-end CLI tests"
    - "tests/validation_tests.rs - Validation workflow tests"

  documentation:
    - "README.md - User-facing documentation"
    - "DESIGN_V1.md - v1.0.0 technical specification"
    - "roadmap.yaml - Development roadmap and progress"
    - "KNOWN_BUGS.md - Bug tracking"
    - "schema/forge-v1.0.schema.json - JSON Schema for v1.0.0"

  examples:
    - "test-data/v1.0/saas_unit_economics.yaml"
    - "test-data/v1.0/quarterly_pl.yaml"
    - "test-data/v1.0/budget_vs_actual.yaml"

advanced_rust_patterns:
  error_handling:
    description: "Type-safe, ergonomic error handling"
    current_approach: "Using thiserror for custom errors"
    best_practices:
      - "Use Result<T, E> everywhere, avoid panics in library code"
      - "Custom error types with thiserror for rich context"
      - "? operator for error propagation"
      - "Pattern match on specific error variants when recovery possible"
      - "Add context with .map_err() when wrapping errors"

    example_pattern: |
      // Good: Rich error context
      #[derive(Error, Debug)]
      pub enum ForgeError {
          #[error("Formula evaluation failed: {0}")]
          Eval(String),

          #[error("Column '{column}' in table '{table}': {reason}")]
          ColumnError {
              column: String,
              table: String,
              reason: String,
          },
      }

    avoid:
      - "Don't use unwrap() or expect() in library code"
      - "Don't use String errors (not type-safe)"
      - "Don't lose error context when propagating"

  type_driven_design:
    description: "Use the type system to prevent bugs at compile time"
    principles:
      - "Make illegal states unrepresentable"
      - "Use newtypes for domain concepts (TableName, ColumnName)"
      - "Prefer enums over booleans for state"
      - "Use builder pattern for complex construction"
      - "Leverage const generics for compile-time guarantees"

    examples:
      invalid_state_impossible: |
        // Bad: Can create invalid state
        struct Table {
            columns: Vec<Column>,
            row_count: usize,  // Could be inconsistent!
        }

        // Good: Validity guaranteed by construction
        struct Table {
            columns: NonEmpty<Vec<Column>>,  // Never empty
            // row_count derived from columns.len()
        }

      newtype_safety: |
        // Prevents mixing up table and column names
        #[derive(Debug, Clone, PartialEq, Eq, Hash)]
        struct TableName(String);

        #[derive(Debug, Clone, PartialEq, Eq, Hash)]
        struct ColumnName(String);

        // Now can't accidentally pass ColumnName where TableName expected!

  zero_copy_optimization:
    description: "Minimize allocations and copies"
    techniques:
      - "Use &str instead of String when possible"
      - "Use Cow<str> for conditional ownership"
      - "Pass large structs by reference"
      - "Use slice patterns for matching"
      - "Consider arena allocation for trees/graphs"

    when_to_use:
      - "Parser should use &str references into input"
      - "Formula evaluation can use Cow for variable names"
      - "Avoid clone() unless necessary - prefer references"

  testing_patterns:
    property_based_testing:
      description: "Test properties that should always hold"
      tool: "proptest or quickcheck"
      install: "cargo add --dev proptest"

      use_cases:
        - "Parser: Any valid v1.0 YAML should parse successfully"
        - "Calculator: SUM(a,b) == SUM(b,a) (commutative)"
        - "Precision: (a + b) - b should equal a within epsilon"
        - "Serialization: parse(serialize(x)) == x (round-trip)"

      example: |
        use proptest::prelude::*;

        proptest! {
            #[test]
            fn test_sum_commutative(a: f64, b: f64) {
                let sum1 = calculate("=SUM(a, b)");
                let sum2 = calculate("=SUM(b, a)");
                assert!((sum1 - sum2).abs() < 1e-10);
            }
        }

    snapshot_testing:
      description: "Test complex outputs against saved snapshots"
      tool: "insta"
      install: "cargo add --dev insta"

      use_cases:
        - "CLI output formatting"
        - "Error messages"
        - "Generated Excel files (metadata)"
        - "Large calculation results"

      workflow:
        - "First run creates snapshot"
        - "Subsequent runs compare to snapshot"
        - "Review changes with cargo insta review"
        - "Commit snapshots to git"

    mutation_testing:
      description: "Test the tests - verify tests catch bugs"
      tool: "cargo-mutants"
      install: "cargo install cargo-mutants"

      what_it_does:
        - "Introduces small bugs (mutations) in code"
        - "Checks if tests catch them"
        - "Reports 'survived mutants' (bugs tests missed)"

      run: "cargo mutants"
      goal: "100% mutation coverage (all mutants caught)"

    fuzzing:
      description: "Find edge cases and crashes automatically"
      tool: "cargo-fuzz"
      setup: "cargo install cargo-fuzz"

      targets:
        - "Parser (feed random YAML)"
        - "Formula evaluator (random formulas)"
        - "Array operations (random data)"

      run: "cargo fuzz run parser_target"
      benefit: "Discovers crashes, panics, edge cases automatically"

  performance_patterns:
    benchmarking:
      tool: "criterion"
      already_added: true

      best_practices:
        - "Benchmark realistic workloads (real YAML files)"
        - "Track performance over time (commit to git)"
        - "Set baseline before optimization"
        - "Profile before optimizing (flamegraph)"
        - "Optimize hot paths only"

      commands:
        bench: "cargo bench"
        compare: "cargo bench --baseline <name>"
        flamegraph: "cargo flamegraph --bench <name>"

    profiling:
      description: "Find actual bottlenecks before optimizing"
      tools:
        linux: "perf, flamegraph"
        mac: "Instruments, cargo-instruments"
        windows: "Windows Performance Analyzer"

      workflow:
        - "cargo build --release"
        - "Run with profiler on realistic input"
        - "Generate flamegraph"
        - "Optimize hot paths only"
        - "Benchmark before/after"

    allocation_tracking:
      tool: "dhat (valgrind)"
      purpose: "Find unnecessary allocations"

      command: "cargo run --release -- <args> | dhat"
      look_for:
        - "Temporary allocations in hot loops"
        - "Clone() that could be reference"
        - "String allocations that could be &str"

  architecture_patterns:
    strategy_pattern:
      description: "Multiple algorithms with same interface"
      current_use: "Calculator (v0.2.0 scalar vs v1.0.0 array)"

      structure: |
        trait Calculator {
            fn calculate(&mut self) -> ForgeResult<CalculationResult>;
        }

        struct ScalarCalculator { /* v0.2.0 */ }
        struct ArrayCalculator { /* v1.0.0 */ }

        impl Calculator for ScalarCalculator { /* ... */ }
        impl Calculator for ArrayCalculator { /* ... */ }

        // Factory function chooses implementation
        fn create_calculator(model: ParsedModel) -> Box<dyn Calculator> {
            match model.version {
                ForgeVersion::V0_2_0 => Box::new(ScalarCalculator::new(model)),
                ForgeVersion::V1_0_0 => Box::new(ArrayCalculator::new(model)),
            }
        }

    builder_pattern:
      description: "Fluent API for complex object construction"
      when_to_use:
        - "Many optional parameters"
        - "Validation during construction"
        - "Default values"

      example: |
        struct TableBuilder {
            name: String,
            columns: Vec<Column>,
            row_formulas: HashMap<String, String>,
        }

        impl TableBuilder {
            fn new(name: impl Into<String>) -> Self { /* ... */ }

            fn add_column(mut self, col: Column) -> Self {
                self.columns.push(col);
                self
            }

            fn add_formula(mut self, name: impl Into<String>, formula: impl Into<String>) -> Self {
                self.row_formulas.insert(name.into(), formula.into());
                self
            }

            fn build(self) -> ForgeResult<Table> {
                // Validate before constructing
                Table::validate_and_create(self)
            }
        }

        // Usage
        let table = TableBuilder::new("sales")
            .add_column(revenue_col)
            .add_column(expenses_col)
            .add_formula("profit", "=revenue - expenses")
            .build()?;

    newtype_pattern:
      description: "Type safety for primitive types"
      benefits:
        - "Can't mix up TableName and ColumnName"
        - "Can implement traits for domain types"
        - "Better error messages"
        - "Self-documenting code"

      example: |
        #[derive(Debug, Clone, PartialEq, Eq, Hash)]
        struct TableName(String);

        impl TableName {
            fn new(name: impl Into<String>) -> ForgeResult<Self> {
                let name = name.into();
                if name.is_empty() {
                    return Err(ForgeError::Parse("Table name cannot be empty".into()));
                }
                Ok(Self(name))
            }

            fn as_str(&self) -> &str {
                &self.0
            }
        }

        // Now function signatures are clearer
        fn get_table(&self, name: &TableName) -> Option<&Table> {
            self.tables.get(name.as_str())
        }

  code_quality_tools:
    essential:
      cargo_audit:
        purpose: "Check for security vulnerabilities in dependencies"
        install: "cargo install cargo-audit"
        run: "cargo audit"
        ci: "Run in GitHub Actions on every PR"

      cargo_deny:
        purpose: "Policy enforcement for deps (licenses, security, duplicates)"
        install: "cargo install cargo-deny"
        setup: "cargo deny init"
        run: "cargo deny check"
        checks:
          - "License compatibility"
          - "Security advisories"
          - "Duplicate dependencies"
          - "Banned crates"

      cargo_machete:
        purpose: "Find unused dependencies"
        install: "cargo install cargo-machete"
        run: "cargo machete"
        why: "Faster builds, smaller binaries, less attack surface"

      cargo_nextest:
        purpose: "Faster test runner (parallel by default)"
        install: "cargo install cargo-nextest"
        run: "cargo nextest run"
        benefits:
          - "Cleaner output"
          - "Faster execution"
          - "Better CI integration"
          - "Flaky test detection"

    advanced:
      miri:
        purpose: "Detect undefined behavior (use-after-free, data races)"
        install: "rustup component add miri"
        run: "cargo miri test"
        when: "Testing unsafe code or complex concurrency"

      cargo_tarpaulin:
        purpose: "Code coverage analysis"
        install: "cargo install cargo-tarpaulin"
        run: "cargo tarpaulin --out Html"
        goal: "Aim for >80% coverage, 100% on critical paths"

  documentation_best_practices:
    humor_and_clarity:
      philosophy: "Make docs memorable and fun while staying professional"
      why: "People remember stories better than specs. Humor reduces intimidation."

      guidelines:
        do:
          - "Use relatable metaphors and analogies"
          - "Add playful examples (rubber ducks, pizza, cats)"
          - "Self-deprecating humor about common mistakes"
          - "Pop culture references (when widely known)"
          - "Celebrate small wins with enthusiasm"
          - "Use emojis sparingly but effectively (ğŸ‰ ğŸ› ğŸš€)"

        dont:
          - "No offensive jokes (politics, religion, demographics)"
          - "No inside jokes that exclude newcomers"
          - "No sarcasm that could confuse (tone is hard in text)"
          - "No jokes at user's expense"
          - "No humor in error messages (user is frustrated!)"

      metaphors_for_common_concepts:
        ownership_and_borrowing: |
          // Ownership is like car keys
          let keys = CarKeys::new();  // You own the keys
          drive_car(&keys);           // Lend keys temporarily (borrow)
          // Keys automatically returned after function
          // Can't lose keys while someone's borrowing them!

        option_vs_result: |
          // Option: SchrÃ¶dinger's cat ğŸ±
          //   Some(cat) = cat is alive!
          //   None = box is empty, no cat

          // Result: Cat delivery service ğŸ“¦
          //   Ok(cat) = cat delivered successfully!
          //   Err(e) = delivery failed (stuck in tree, wrong address, etc.)

        iterators: |
          // Iterators are like assembly lines
          vec.iter()              // Put items on conveyor belt
             .filter(|x| x > 10)  // Quality control station
             .map(|x| x * 2)      // Processing station
             .collect()           // Package at end of line

        closures: |
          // Closures are like food trucks
          let pizza_truck = |toppings| {
              make_pizza(toppings)  // Captures make_pizza from environment
          };
          // Food truck can be called anywhere, brings its equipment!

        trait_objects: |
          // Trait objects are like power outlets
          // Don't care if it's a phone, laptop, or toaster
          // As long as it implements the "can plug in" trait!
          fn charge(device: &dyn Chargeable) {
              device.charge();  // Works for any chargeable device
          }

      example_doc_comments:
        boring: |
          /// Parses a YAML file and returns a ParsedModel.
          pub fn parse_model(path: &Path) -> ForgeResult<ParsedModel>

        with_personality: |
          /// Parses a YAML file into a delicious `ParsedModel` sandwich ğŸ¥ª
          ///
          /// Think of this as your YAML â†’ Rust translator. Reads the YAML,
          /// checks if it's the new hotness (v1.0.0 arrays) or the classic
          /// recipe (v0.2.0 scalars), and serves it up in a type-safe wrapper.
          ///
          /// # Examples
          ///
          /// ```no_run
          /// // Feed it a YAML file, get back a structured model
          /// let model = parse_model(Path::new("quarterly_financials.yaml"))?;
          ///
          /// // Now you can work with typed data instead of raw strings!
          /// assert_eq!(model.version, ForgeVersion::V1_0_0);
          /// ```
          ///
          /// # Errors
          ///
          /// This function is a bit picky (in a good way!):
          /// - If the YAML is malformed, it'll let you know immediately
          /// - If arrays have mixed types, it'll stop you before bad things happen
          /// - If columns have different lengths, it'll save you from Excel export sadness
          ///
          /// Think of errors as your friendly neighborhood validator ğŸ¦¸
          pub fn parse_model(path: &Path) -> ForgeResult<ParsedModel>

      README_personality_examples:
        technical_but_fun: |
          ## Why Forge?

          Because AI hallucinates, and your CFO doesn't appreciate creative accounting. ğŸ“Š

          Forge is like a spell-checker for your financial formulas. It won't let you
          ship a model where `revenue - expenses = unicorns`. (We tried. It didn't work.)

          **Problem:** You have 1,140 formulas in your financial model. Excel says they're
          all fine. Excel is lying. ğŸ¤¥

          **Solution:** Forge validates EVERY formula BEFORE you send it to investors.
          No more "Oops, we accidentally calculated our valuation in dog years."

        feature_descriptions: |
          ## Features That Spark Joy âœ¨

          ### ğŸ¯ Excel-Compatible Formulas
          All your favorite hits: SUM, AVERAGE, IF, and friends. They work exactly
          like Excel, minus the existential dread of `#REF!` errors.

          ### ğŸ”’ Type-Safe Arrays
          Forge won't let you mix numbers with text. Because `["Q1", 42, true]` is
          not a valid dataset, it's a cry for help.

          ### âš¡ Blazingly Fastâ„¢
          Validates 1,140 formulas in <200ms. That's faster than Excel can say
          "Not Responding" on your coworker's laptop.

          ### ğŸ“ Zero Error Tolerance
          Your model either works perfectly or tells you exactly what's wrong.
          No "works on my machine" shenanigans.

      error_message_guidelines:
        important_note: "Error messages should be HELPFUL, not funny. User is already frustrated!"

        error_message_structure: |
          // Structure: What went wrong + Why + How to fix
          ForgeError::Parse(format!(
              "Column '{}' has mixed types (found Number and Text). \n\
               All values in an array must be the same type for Excel export. \n\
               Tip: Use separate columns for different data types.",
              column_name
          ))

        do_in_errors:
          - "Be specific about what went wrong"
          - "Explain why it's a problem"
          - "Suggest how to fix it"
          - "Show the problematic value if helpful"
          - "Use friendly language ('Tip:', 'Note:')"

        dont_in_errors:
          - "Don't use humor or sarcasm"
          - "Don't blame the user ('you did X wrong')"
          - "Don't use jargon without explanation"
          - "Don't just say 'invalid input' - be specific!"

      comments_in_code:
        good_comments: |
          // Why xlformula_engine uses f32: Excel's native number format
          // We round to 6 decimals to avoid issues like 0.9 showing as 0.8999999
          // This is a reasonable tradeoff for financial calculations (max error: Â±0.0001%)

          // TODO: Implement SUMIF after basic aggregation works
          // (Don't want to run before we can walk!)

          // HACK: xlformula_engine doesn't understand @ for cross-file refs
          // So we temporarily replace @ with _ and convert back in resolver
          // It's like using a fake mustache to sneak past a bouncer ğŸ¥¸

        bad_comments: |
          // This is bad
          let x = 5;

          // Loop through items (duh, I can read the code!)
          for item in items {

          // Magic number (WHY?! What does 42 represent?)
          if count > 42 {

      git_commit_messages_with_personality:
        boring: "Fix bug in parser"

        better: "Fix parser crash on empty arrays"

        best: |
          Fix parser panic when encountering empty column arrays

          The parser was assuming all arrays had at least one element (rookie
          mistake!). This caused a panic when users had placeholder columns.

          Now we check for empty arrays and return a helpful error instead of
          crashing like a Windows 95 screensaver.

          Added test: test_empty_array_error

          ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

          Co-Authored-By: Claude <noreply@anthropic.com>

    rustdoc:
      principles:
        - "Every public item should have doc comment (with personality!)"
        - "Start with one-line summary, then tell a story"
        - "Include examples in doc comments (they're tested!)"
        - "Use /// for items, //! for modules"
        - "Link to related items with [Type]"
        - "Add metaphors and analogies for complex concepts"
        - "Celebrate what the code does well"

      example: |
        /// Calculates all formulas in a v1.0.0 array model.
        ///
        /// This calculator handles row-wise (element-wise) operations on column arrays,
        /// with automatic dependency resolution within tables.
        ///
        /// # Examples
        ///
        /// ```no_run
        /// use royalbit_forge::core::ArrayCalculator;
        /// use royalbit_forge::parser::parse_model;
        /// use std::path::Path;
        ///
        /// let model = parse_model(Path::new("model.yaml"))?;
        /// let calculator = ArrayCalculator::new(model);
        /// let result = calculator.calculate_all()?;
        /// # Ok::<(), royalbit_forge::error::ForgeError>(())
        /// ```
        ///
        /// # Errors
        ///
        /// Returns [`ForgeError::Eval`] if formula evaluation fails.
        /// Returns [`ForgeError::CircularDependency`] if circular refs detected.
        pub fn calculate_all(mut self) -> ForgeResult<ParsedModel> {
            // ...
        }

      check: "cargo doc --no-deps --open"

    architecture_decision_records:
      description: "Document significant architectural decisions"
      format: "ADRs in docs/adr/ directory"

      template: |
        # ADR-001: Use xlformula_engine for Excel Compatibility

        ## Status
        Accepted (2025-11-23)

        ## Context
        Need Excel-compatible formula evaluation for v0.2.0.
        Options: meval (simple), evalexpr, xlformula_engine.

        ## Decision
        Use xlformula_engine despite f32 precision concerns.

        ## Consequences
        + Excel compatibility
        + Rich formula library
        - f32 precision (mitigated with rounding)
        - External dependency maintenance

      when_to_write:
        - "Major library choices"
        - "Architectural patterns"
        - "Breaking changes"
        - "Performance trade-offs"

tips_for_success:
  critical:
    - "ğŸš¨ CHECK CURRENT DATE in <env> before ANY online search!"
    - "ZERO warnings policy - treat warnings as errors (user has OCD for clean code ğŸ˜Š)"
    - "Run cargo audit before releases (no surprises from dependency CVEs)"

  planning:
    - "Think harder before implementing - measure twice, code once ğŸ“"
    - "BEFORE complex code: Search crates.io (don't reinvent the wheel, it's already round)"
    - "Profile before optimizing - premature optimization is the root of all evil (and wasted time)"
    - "Read DESIGN_V1.md - it's 800+ lines for a reason!"

  testing:
    - "Write tests first when possible (TDD = sleep better at night)"
    - "Test edge cases - empty arrays, nulls, invalid inputs (Murphy's Law is undefeated)"
    - "Consider property-based testing for complex logic (test the rules, not examples)"
    - "If a bug makes it to production, write a test so it never comes back (revenge testing!)"

  type_safety:
    - "Use type system to prevent bugs (make illegal states unrepresentable)"
    - "Newtypes are your friends (TableName â‰  ColumnName, even though both are strings)"
    - "Enums over booleans (states > true/false)"
    - "Builder pattern for complex construction (fluent APIs are a joy to use)"

  code_quality:
    - "Run clippy frequently (it's like having a pedantic friend who's always right)"
    - "cargo fmt before every commit (consistency = readability)"
    - "No unwrap() in library code (Result<T,E> or bust)"
    - "Comments should explain WHY, not WHAT (code shows what, you explain why)"

  documentation:
    - "Update docs as you code, not after (future you will thank present you)"
    - "Add personality to docs - make them memorable (car keys, food trucks, cats ğŸ±)"
    - "Examples in rustdoc are tested (free test coverage!)"
    - "Error messages: helpful, not funny (user is frustrated, not entertained)"

  workflow:
    - "Commit frequently with descriptive messages (tell a story, not a changelog)"
    - "Use TodoWrite to track progress (Claude's memory needs help)"
    - "Check KNOWN_BUGS.md before fixing (might already be documented)"
    - "One feature per commit (atomic changes = easy reverts)"

  collaboration:
    - "Ask user for clarification on ambiguous requirements (assumptions are dangerous)"
    - "Check license compatibility (MIT-compatible only, GPL is the Voldemort of licenses)"
    - "When stuck, explain the problem out loud (rubber duck debugging works!)"

  wisdom:
    - "If it compiles in Rust, it probably works (type system FTW)"
    - "If tests pass but feel fragile, trust your instincts"
    - "Simpler code > clever code (cleverness is hard to debug at 2am)"
    - "When in doubt, add a test (tests never lie)"
    - "Break before optimize, fix before enhance, test before merge"

collaboration_notes:
  user_preferences:
    - "User values: zero errors, 100% accuracy, thorough testing"
    - "User has OCD for beautiful code - ZERO warnings, strict linting"
    - "User says 'Punch it!' when ready to proceed"
    - "User says 'Think harder' when wanting deeper analysis"
    - "User provides context from previous sessions via summary"
    - "Always check current date before online searches (training data is old!)"

session_end_checklist:
  - "â˜ All tests passing"
  - "â˜ All changes committed"
  - "â˜ Changes pushed to remote"
  - "â˜ Roadmap updated if phase progress changed"
  - "â˜ TodoWrite list reflects accurate status"
  - "â˜ User knows current status and next steps"

grant_opportunities:
  description: "Canadian grant funding for Forge + Warmup Protocol innovation"
  company_status:
    ownership: "51% Kantia Tavares (woman-owned), 49% Louis Tavares"
    location: "Montreal, Quebec, Canada"
    qualification: "Triple advantage: Technology innovation + Woman-owned + Quebec location"

  total_potential: "$760K-$1.4M over 3 years"

  documentation:
    primary: "docs/CANADIAN_GRANT_OPPORTUNITIES.md (comprehensive 760-line guide)"
    research: "docs/GRANT_RESEARCH_2025-11-24.md (fresh 2025-11-24 online search)"
    sred_log: "SRED_RESEARCH_LOG.md (1,420+ lines, 7 completed experiments)"

  priority_programs:
    tier_1_immediate:
      irap:
        name: "NRC IRAP (Industrial Research Assistance Program)"
        value: "$300K-$500K"
        coverage: "80% salaries, 50% contractors (non-repayable)"
        contact: "1-877-994-4727"
        action: "Call January 2026 for initial assessment"
        why: "Perfect fit for autonomous AI protocol R&D"

      sred:
        name: "SR&ED Tax Credits (Federal + Quebec)"
        value: "$130K+/year (refundable)"
        coverage: "Federal 35% + Quebec 30% = 65% of R&D costs"
        timeline: "File with 2025 tax return (June 2026)"
        status: "Already documented in SRED_RESEARCH_LOG.md"

      ai_compute_fund:
        name: "AI Compute Access Fund (NEW 2025!)"
        value: "$100K-$5M over 3 years"
        coverage: "66% domestic cloud, 50% foreign cloud"
        launched: "March 2025"
        why: "Warmup Protocol is AI methodology innovation"

    tier_2_woman_owned:
      bmo_celebrating_women:
        name: "BMO Celebrating Women Grant"
        value: "$10K + summit invitation"
        window: "August 5-19, 2025 (8am-8pm Eastern)"
        eligibility: "51%+ women-owned (Kantia 51% âœ…)"
        action: "CRITICAL: Set calendar reminder for Aug 5-19, 2025"

      bombardier_excellence:
        name: "J. Armand Bombardier Excellence Grants"
        value: "$10K"
        deadline: "Typically January 15"
        eligibility: "50%+ women, 1-5 years, Quebec, tech innovation (âœ… all qualify)"
        action: "Apply January 2026"

      femmessor:
        name: "Femmessor Quebec"
        value: "Up to $50K in micro-loans + grants"
        eligibility: "25%+ women ownership (Kantia 51% âœ…)"
        why: "Quebec women entrepreneurs"

    tier_3_quebec_montreal:
      prompt_ai:
        name: "PROMPT AI Programs (Quebec)"
        value: "Up to $1.5M"
        coverage: "50% startups, 35% SMEs"
        focus: "AI innovation projects"

      pso:
        name: "Support Program for Research and Innovation (PSO)"
        value: "$1.5M over 3 years ($500K/year max)"
        coverage: "Up to 40% of costs"
        focus: "Innovation-driven technology sectors"

      montreal_innovation:
        name: "Montreal Innovation Fund"
        value: "Up to $50K"
        coverage: "80% of project cost"
        focus: "Innovation commercialization, technological equipment"

      pme_mtl:
        name: "PME MTL Programs"
        value: "$40K-$60K"
        coverage: "75% of expenses"
        focus: "Eco-responsible practices, clean technology"

  key_advantages:
    technological_innovation:
      forge: "YAML formula calculator with Excel bridge (solves $40K-$132K/year AI hallucination costs)"
      warmup_protocol: "World's first autonomous AI development methodology (3-4x velocity, 0% rework)"
      validation: "v1.0.0 built in 2 weeks autonomously, ZERO bugs, 100 tests passing"

    woman_owned_business:
      status: "51% Kantia Tavares ownership"
      qualification: "Meets woman-owned criteria for BMO, Bombardier, Femmessor, Federal programs"
      additional_streams: "Access to woman entrepreneur grants across federal, provincial, municipal"

    quebec_location:
      advantage: "Access to federal + provincial + municipal programs"
      programs: "PROMPT, PSO, Montreal Innovation Fund, PME MTL, IRAP, SR&ED"

    open_source_foss:
      license: "MIT (open source)"
      publication: "Published on crates.io (Rust package registry)"
      benefit: "Demonstrates broader community impact for grant applications"

    proven_results:
      production: "$200K+ grant funding protected from AI hallucinations"
      quality: "ZERO bugs shipped, 100% test coverage, ZERO warnings"
      velocity: "3-4x development speed, 0% rework (vs industry 30-50%)"
      documentation: "1,420+ line SR&ED research log with 7 completed experiments"

  immediate_actions:
    calendar_reminders:
      - "âš ï¸ CRITICAL: BMO Celebrating Women Grant (August 5-19, 2025)"
      - "J. Armand Bombardier deadline (typically January 15, 2026)"

    phone_calls:
      - "IRAP initial assessment: 1-877-994-4727 (call January 2026)"

    applications:
      - "AI Compute Access Fund (apply Q1 2026)"
      - "PROMPT AI Programs (check intake dates)"
      - "Montreal Innovation Fund (ongoing applications)"

    documentation:
      - "Continue SR&ED research log (file with 2025 taxes June 2026)"
      - "Prepare company documents (incorporation, ownership proof)"
      - "Draft IRAP project proposal (Forge v1.1.0 + Protocol productization)"

  selling_points:
    elevator_pitch: |
      RoyalBit Inc. has developed two Canadian technological breakthroughs:

      1. Forge: Open-source YAML formula calculator solving $40K-$132K/year AI hallucination costs
      2. Warmup Protocol: World's first autonomous AI development methodology (3-4x velocity, 0% rework)

      Woman-owned (51% Kantia), Montreal-based, open source (MIT), production-proven, fully documented.

      This isn't incremental improvement. This is paradigm shift from 'AI assists developer' to 'AI IS developer.'

    quantifiable_results:
      velocity: "20-50x faster than traditional (conservative: 3-4x)"
      quality: "ZERO warnings, 100% test coverage, 0 bugs shipped"
      rework: "0% (vs. industry standard 30-50%)"
      cost_savings: "$40K-$132K/year for enterprise users"
      efficiency: "97% reduction in human oversight time"
      time_to_market: "3-6 months â†’ 2 weeks"

  notes:
    - "Woman-owned status (51% Kantia) opens significant additional grant streams"
    - "Quebec location provides triple access: federal + provincial + municipal"
    - "Open source publication strengthens 'advancement of knowledge' criterion for SR&ED"
    - "Warmup Protocol represents genuine technological breakthrough (not just tool development)"
    - "Total potential: $760K-$1.4M over 3 years across all programs"
